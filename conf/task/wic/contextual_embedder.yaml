defaults:
  - scaler: ???
  - normalization: ???
  - dist_fn@similarity_metric: ???

_target_: src.wic.ContextualEmbedder
layers: [1, 12]
layer_aggregation: average
subword_aggregation: average
truncation_tokens_before_target: 0.5


gpu: null
ckpt: ???

cache:
  _target_: src.wic.contextual_embedder.Cache
  metadata:
    dataset:
      name: ${dataset.name}
      preprocessing: ${dataset.preprocessing.name}
      spelling_normalization: ${dataset.spelling_normalization}
    contextual_embedder:
      pre_target_tokens: ${....truncation_tokens_before_target}
      ckpt: ${....ckpt}

